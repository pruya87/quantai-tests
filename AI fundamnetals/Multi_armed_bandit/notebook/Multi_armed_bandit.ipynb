{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOeVrR2oN2-f"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "class MultiArmedBandit:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        # Random true probabilities of winning for each arm, unknown to the agent\n",
    "        self.probs = np.random.rand(k)\n",
    "\n",
    "    def pull(self, arm):\n",
    "        # Return reward 1 with probability probs[arm], else 0\n",
    "        return 1 if np.random.rand() < self.probs[arm] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kb2UsPbnN6ve"
   },
   "outputs": [],
   "source": [
    "mab = MultiArmedBandit(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYbA55BNOavH"
   },
   "outputs": [],
   "source": [
    "class EpsilonGreedyAgent:\n",
    "    def __init__(self, k, epsilon):\n",
    "        self.k = k\n",
    "        self.epsilon = epsilon\n",
    "        self.counts = np.zeros(k)  # Number of times each arm was played\n",
    "        self.values = np.zeros(k)  # Estimated value (mean reward) for each arm\n",
    "\n",
    "    def select_arm(self):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # Explore\n",
    "            return np.random.randint(self.k)\n",
    "        else:\n",
    "            # Exploit\n",
    "            return np.argmax(self.values)\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        self.counts[arm] += 1\n",
    "        n = self.counts[arm]\n",
    "        value = self.values[arm]\n",
    "        # Update estimated value with incremental formula\n",
    "        self.values[arm] = value + (reward - value) / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLsPBvq3QleZ"
   },
   "outputs": [],
   "source": [
    "class UCBAgent:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.counts = np.zeros(k)  # Number of times each arm was played\n",
    "        self.values = np.zeros(k)  # Estimated value (mean reward) for each arm\n",
    "        self.total_counts = 0\n",
    "\n",
    "    def select_arm(self):\n",
    "        self.total_counts += 1\n",
    "        # Play each arm once to initialize\n",
    "        for arm in range(self.k):\n",
    "            if self.counts[arm] == 0:\n",
    "                return arm\n",
    "\n",
    "        ucb_values = self.values + np.sqrt(2 * np.log(self.total_counts) / self.counts)\n",
    "        return np.argmax(ucb_values)\n",
    "    \"\"\"\n",
    "         Values 2 factors:\n",
    "         self.values (how well the arm has done so far)\n",
    "         np.sqrt(2 * np.log(self.total_counts) / self.counts) (uncertainty factor ==> bigger the less the arm has been used)\n",
    "    \"\"\"\n",
    "\n",
    "    def update(self, arm, reward):\n",
    "        self.counts[arm] += 1\n",
    "        n = self.counts[arm]\n",
    "        value = self.values[arm]\n",
    "        self.values[arm] = value + (reward - value) / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b82cTMTlOb6A"
   },
   "outputs": [],
   "source": [
    "def run_simulation(k=10, agent='epsilon', epsilon=0.1, steps=1000):\n",
    "    bandit = MultiArmedBandit(k)\n",
    "    if agent == 'epsilon':\n",
    "        agent = EpsilonGreedyAgent(k, epsilon)\n",
    "    elif agent == 'ucb':\n",
    "        agent = UCBAgent(k)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown agent type: {agent}\")\n",
    "    rewards = np.zeros(steps)\n",
    "    chosen_arms = np.zeros(steps, dtype=int)\n",
    "\n",
    "    for t in range(steps):\n",
    "        arm = agent.select_arm()\n",
    "        reward = bandit.pull(arm)\n",
    "        agent.update(arm, reward)\n",
    "        rewards[t] = reward\n",
    "        chosen_arms[t] = arm\n",
    "\n",
    "    print(\"True probabilities of arms:\", np.round(bandit.probs, 3))\n",
    "    print(\"Estimated values:\", np.round(agent.values, 3))\n",
    "\n",
    "    # Plot cumulative average reward\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(np.cumsum(rewards) / (np.arange(steps) + 1))\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Average reward')\n",
    "    plt.title(f'Cumulative average reward (epsilon={epsilon})')\n",
    "\n",
    "    # Plot counts of chosen arms\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.bar(range(k), agent.counts)\n",
    "    plt.xlabel('Arm')\n",
    "    plt.ylabel('Times chosen')\n",
    "    plt.title('Number of times each arm was chosen')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "8cCjcoRyPA1-",
    "outputId": "271bd615-9e05-4b59-f42c-aae6e88bf0bf"
   },
   "outputs": [],
   "source": [
    "run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "LAi8erwZStnR",
    "outputId": "e6b94f87-43e8-4b7a-e3de-d5b7015945f0"
   },
   "outputs": [],
   "source": [
    "run_simulation(agent='ucb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "vZPmgOILWg3Q",
    "outputId": "300bdc9c-1fb6-4d3b-b515-c143809aeda5"
   },
   "outputs": [],
   "source": [
    "######### ANIMATED AGENT ###############\n",
    "\n",
    "def animate_bandit(agent_class, k=10, steps=200, epsilon=0.1):\n",
    "    bandit = MultiArmedBandit(k)\n",
    "    if agent_class == 'epsilon':\n",
    "        agent = EpsilonGreedyAgent(k, epsilon)\n",
    "    elif agent_class == 'ucb':\n",
    "        agent = UCBAgent(k)\n",
    "    else:\n",
    "        raise ValueError('Unknown agent')\n",
    "\n",
    "    rewards = []\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim(0, steps)\n",
    "    ax.set_ylim(0, 1)\n",
    "    line, = ax.plot([], [], lw=2)\n",
    "    ax.set_xlabel('Step')\n",
    "    ax.set_ylabel('Cumulative Average Reward')\n",
    "    ax.set_title(f'Learning Curve ({agent_class}, epsilon={epsilon})')\n",
    "\n",
    "    def update(frame):\n",
    "        arm = agent.select_arm()\n",
    "        reward = bandit.pull(arm)\n",
    "        agent.update(arm, reward)\n",
    "        rewards.append(reward)\n",
    "        avg_reward = sum(rewards) / len(rewards)\n",
    "        line.set_data(range(len(rewards)), [sum(rewards[:i+1])/(i+1) for i in range(len(rewards))])\n",
    "        return line,\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=steps, blit=True, interval=50)\n",
    "\n",
    "    return HTML(anim.to_jshtml())  # Return HTML for notebook rendering\n",
    "\n",
    "# Call the function and display animation\n",
    "animate_bandit('epsilon', k=10, steps=300, epsilon=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tEwNlJi4jHpC",
    "outputId": "d2b8174b-f546-4363-f673-de58547445da"
   },
   "outputs": [],
   "source": [
    "def ucb_scores(mean_rewards, counts, total_counts):\n",
    "    # mean_rewards: array of average rewards per arm\n",
    "    # counts: array of times each arm was played\n",
    "    # total_counts: current time step\n",
    "    ucb_vals = []\n",
    "    for i in range(len(mean_rewards)):\n",
    "        if counts[i] == 0:\n",
    "            # Force exploration of unplayed arms\n",
    "            ucb_vals.append(np.inf)\n",
    "        else:\n",
    "            bonus = np.sqrt(2 * np.log(total_counts) / counts[i])\n",
    "            ucb_vals.append(mean_rewards[i] + bonus)\n",
    "    return np.array(ucb_vals)\n",
    "\n",
    "# Example fixed mean rewards\n",
    "mean_rewards = np.array([0.2, 0.5, 0.8])\n",
    "\n",
    "# Let's simulate pulls and total counts\n",
    "pulls_per_arm = [\n",
    "    [1, 5, 10, 20],  # example pulls for arm 0\n",
    "    [1, 5, 10, 20],  # arm 1\n",
    "    [1, 5, 10, 20],  # arm 2\n",
    "]\n",
    "\n",
    "total_counts = [3, 10, 20, 40]  # total steps increasing\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for idx, arm in enumerate(range(3)):\n",
    "    scores = []\n",
    "    for total, count in zip(total_counts, pulls_per_arm[arm]):\n",
    "        scores.append(ucb_scores(mean_rewards, np.array([pulls_per_arm[0][total_counts.index(total)],\n",
    "                                                       pulls_per_arm[1][total_counts.index(total)],\n",
    "                                                       pulls_per_arm[2][total_counts.index(total)]]),\n",
    "                                total)[arm])\n",
    "    plt.plot(total_counts, scores, label=f'Arm {arm} (mean={mean_rewards[arm]:.1f})')\n",
    "\n",
    "plt.xlabel('Total Steps (t)')\n",
    "plt.ylabel('UCB Score')\n",
    "plt.title('UCB Scores for Different Arms Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
