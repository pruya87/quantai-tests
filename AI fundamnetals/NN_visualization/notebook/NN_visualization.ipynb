{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGsQXkxcKtOx",
    "outputId": "16880bef-f5ab-4e3d-bf1e-a4ec7df3878b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "print(np.random.seed(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3BYEe9oYVY5"
   },
   "source": [
    "w is the weight (how strongly the input influences the output)\n",
    "\n",
    "X is your input data (in this case, the x-values along the line)\n",
    "\n",
    "b is the bias (shifts the function left/right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "ZUOnmn6IVBUi",
    "outputId": "a9636a83-3166-4cfd-9067-5febd0797c2b"
   },
   "outputs": [],
   "source": [
    "######## NN visualization #################\n",
    "\n",
    "\n",
    "# Create synthetic data\n",
    "np.random.seed(0)\n",
    "n_points = 100\n",
    "X = np.linspace(-5, 5, n_points) # X represents the input\n",
    "# True label: class 0 for x < 0, class 1 for x >= 0, with some noise\n",
    "y = (X > 0).astype(int)\n",
    "\n",
    "# Initialize parameters\n",
    "w = 0.0  # weight\n",
    "b = 0.0  # bias\n",
    "lr = 0.1  # learning rate\n",
    "\n",
    "# sigmoid returns:\n",
    "# near 0 for large negative numbers\n",
    "# near 1 for large positive numbers\n",
    "# near .5 for numbers near 0\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# For storing parameter history to animate\n",
    "ws, bs = [], []\n",
    "losses = []\n",
    "\n",
    "# Training function: one step gradient descent on binary cross-entropy loss\n",
    "def train_step(w, b, X, y):\n",
    "    # Calculate output (z) for each input (X)\n",
    "    z = w * X + b\n",
    "    y_pred = sigmoid(z)\n",
    "\n",
    "    # Binary cross entropy loss between real target (y) and predicted target (y_pred)\n",
    "    loss = -np.mean(y * np.log(y_pred + 1e-8) + (1 - y) * np.log(1 - y_pred + 1e-8))\n",
    "\n",
    "    # Gradients\n",
    "    # dz is the error term (difference between predicted and true labels).\n",
    "    # dw is the gradient of loss w.r.t. weight: It averages over all points how much changing w affects loss.\n",
    "    # db is the gradient w.r.t bias (averaged error).\n",
    "\n",
    "    dz = y_pred - y\n",
    "    dw = np.mean(dz * X)\n",
    "    db = np.mean(dz)\n",
    "\n",
    "    # Update weights and bias. Move weights against gradient to minimize loss\n",
    "    w_new = w - lr * dw\n",
    "    b_new = b - lr * db\n",
    "    return w_new, b_new, loss\n",
    "\n",
    "# Run training and store history\n",
    "for _ in range(50):\n",
    "    w, b, loss = train_step(w, b, X, y)\n",
    "    ws.append(w)\n",
    "    bs.append(b)\n",
    "    losses.append(loss)\n",
    "\n",
    "# Plotting and animation\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "def update(frame):\n",
    "    ax.clear()\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.set_title(f'Training step: {frame+1}\\nWeight: {ws[frame]:.3f}, Bias: {bs[frame]:.3f}, Loss: {losses[frame]:.3f}')\n",
    "    ax.set_xlabel('Input x')\n",
    "    ax.set_ylabel('Neuron output (sigmoid)')\n",
    "\n",
    "    # Plot data points\n",
    "    ax.scatter(X[y==0], y[y==0], color='red', label='Class 0')\n",
    "    ax.scatter(X[y==1], y[y==1], color='blue', label='Class 1')\n",
    "\n",
    "    # Plot neuron output curve\n",
    "    x_vals = np.linspace(-6, 6, 300)\n",
    "    y_vals = sigmoid(ws[frame] * x_vals + bs[frame])\n",
    "    ax.plot(x_vals, y_vals, label='Neuron output', color='green')\n",
    "\n",
    "    # Plot decision boundary: x where output=0.5 → wx + b = 0 → x = -b/w (if w!=0)\n",
    "    if ws[frame] != 0:\n",
    "        db_line = -bs[frame]/ws[frame]\n",
    "        ax.axvline(db_line, color='purple', linestyle='--', label='Decision boundary')\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(ws), interval=300)\n",
    "plt.close()  # Prevent extra static plot\n",
    "\n",
    "HTML(ani.to_jshtml())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
